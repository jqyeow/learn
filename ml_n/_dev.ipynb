{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "\n",
    "samplesize = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mengweetan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def _gender(data):\n",
    "    try:\n",
    "        if data and data.lower()=='male': return 1\n",
    "        else: return 0\n",
    "    except: return -1\n",
    "    \n",
    "def _age(data):\n",
    "    try:\n",
    "        if data and str(data) !='nan':\n",
    "            bd = parse(data)\n",
    "            diff = datetime.now() - bd\n",
    "            return diff.days \n",
    "        else: return 0\n",
    "    except Exception as e: \n",
    "        print (e)\n",
    "        print (data)\n",
    "        return -1\n",
    "    \n",
    "def _nationality(data):\n",
    "    if data and 'singapore' in data.lower(): return 1   \n",
    "    else: return 0\n",
    "    \n",
    "def _resi_status(data):\n",
    "    if data and  data.lower() == 'citizen' or  data.lower() == 'pr': return 1   \n",
    "    else: return 0\n",
    "    \n",
    "def _yesno(data):\n",
    "    if data:\n",
    "        if str(data).lower() == 'yes' : return 1 \n",
    "        else: return 0\n",
    "    else: return -1\n",
    "    \n",
    "def _occupation(data):\n",
    "    if data and 'tour' in str(data).lower(): return 1   \n",
    "    else: return 0\n",
    "    \n",
    "def _self_employ_time(data):\n",
    "    import calendar\n",
    "    try:\n",
    "        if data and str(data) != 'nan':\n",
    "            \n",
    "            \n",
    "            _m = list(calendar.month_abbr).index(data.split(\";\")[0]) \n",
    "\n",
    "            \n",
    "\n",
    "            __y = data.split(\";\")[1].replace('Before','').replace(' ','') # get rid of silly \"Before\"\n",
    "            _y = int(__y)\n",
    "\n",
    "            #print ( (datetime.now() -   datetime(_y,_m,1)).days)\n",
    "            return (datetime.now() -   datetime(_y,_m,1)).days\n",
    "            #else: \n",
    "            #    ym = data.split(';')[2]\n",
    "            #    _y = int(ym.split(\"-\")[0])\n",
    "            #    _m = int(ym.split(\"-\")[1])\n",
    "            #    return (datetime.now() -   datetime(_y,_m,1)).days\n",
    "                \n",
    "        else: return 0\n",
    "    except Exception as e: \n",
    "        print ('mthyear exception')\n",
    "        print (data)\n",
    "        print (e)\n",
    "        return 0\n",
    "    \n",
    "def _log(data):\n",
    "    try:\n",
    "        #print (para)\n",
    "        if data and float(data)>0:return math.log10(float(data))\n",
    "        else: return 0\n",
    "    except Exception as e: \n",
    "        #print (e)\n",
    "        return -1\n",
    "def _int(data):\n",
    "    if data and str(data) != 'nan': return int(data)\n",
    "    else: return 0\n",
    "    \n",
    "    \n",
    "from textblob import TextBlob #sentiment analysis\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import statistics\n",
    "def _sentiment_of(text):\n",
    "    if text:\n",
    "        blob = TextBlob(str(text))\n",
    "        _sentiments = []\n",
    "        for sentence in blob.sentences:\n",
    "            _sentiments.append(sentence.sentiment.polarity)\n",
    "        return  statistics.mean(_sentiments) \n",
    "    else: return -99\n",
    "    \n",
    "def _interested(data):\n",
    "    if data and 'contact' in str(data): return 1\n",
    "    else: return 0\n",
    "    \n",
    "def _label_outcome(data):\n",
    "    if data:\n",
    "        if str(data) == 'Approve - 1000': return 1000\n",
    "        elif str(data) == 'Approve - 800': return 800\n",
    "        elif str(data) == 'Approve - 400': return 400\n",
    "        else: return 0\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengweetan/Desktop/devt/ai/env/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/mengweetan/Desktop/devt/ai/env/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/mengweetan/Desktop/devt/ai/env/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/mengweetan/Desktop/devt/ai/env/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('output2.csv', dtype='unicode') # this is the final file!\n",
    "\n",
    "\n",
    "_result = df[0:samplesize]\n",
    "\n",
    "old_columns = [i for i in _result.columns]\n",
    "\n",
    "_result['_gender']=_result['Gender'].apply(_gender)\n",
    "_result['_age']=_result['Date of Birth'].apply(_age)\n",
    "_result['_nationality']=_result['Nationality'].apply(_nationality)\n",
    "_result['_resi_status']=_result['Residential Status'].apply(_resi_status)\n",
    "\n",
    "_result = pd.concat([_result,pd.get_dummies(_result['Housing Type'], prefix='onehot')],axis=1)\n",
    "_result['_hdb_registered_address']=_result['Registered Address'].apply(_yesno)\n",
    "_result = pd.concat([_result,pd.get_dummies(_result['Highest Education'], prefix='onehot')],axis=1)\n",
    "_result['_occupation']=_result['Occupation'].apply(_occupation)\n",
    "#_result['_av']=_result['Annual Value (AV) of  registered address'].apply(_av,args=(-1,))\n",
    "_result['_av_value']=_result['Annual Value (AV) of  registered address'].apply(_log)\n",
    "\n",
    "_result['__temp']=_result['Self Employed Since (Month)']+';'+_result['Self Employed Since (Year)']\n",
    "_result['_self_employ_time']=_result['__temp'].apply(_self_employ_time)\n",
    "\n",
    "_result['_2018_t']=_result['Income in 2018 (NOA YA2019) - Trade income'].apply(_log)\n",
    "_result['_2018_e']=_result['\\xa0Income in 2018 (NOA YA2019) - Employment income'].apply(_log)\n",
    "_result['_2019_e']=_result['Income in 2019 (NOA YA2020) - Trade income'].apply(_log)\n",
    "_result['_2019_t']=_result['Income in 2019 (NOA YA2020) - Employment income'].apply(_log)\n",
    "_result['_2020_e']=_result['Income in 2020 (Jan-Mar) - Trade income'].apply(_log)\n",
    "_result['_2020_t']=_result['Income in 2020 (Jan-Mar) - Employment income'].apply(_log)\n",
    "_result['s_2019_i']=_result['Spouse\\'s Income in 2019'].apply(_log)\n",
    "_result['s_2020_i']=_result['Spouse\\'s Income in 2020 (Jan-Mar)'].apply(_log)\n",
    "\n",
    "_result['_child']=_result['No. of Singaporean Children < 21'].apply(_int)\n",
    "_result['_parent']=_result['No. of Singaporean Parents > 64'].apply(_int)\n",
    "\n",
    "_result = pd.concat([_result,pd.get_dummies(_result['Marital Status'], prefix='onehot')],axis=1)\n",
    "_result['_married']=_result['Marriage Date'].apply(_age)\n",
    "_result['_divorced']=_result['Divorce Date'].apply(_age)\n",
    "\n",
    "_result['_hdb']=_result['Number of HDB properties own'].apply(_int)\n",
    "_result['_pte']=_result['Number of private properties own'].apply(_int)\n",
    "_result['_comz']=_result['Number of commercial properties own'].apply(_int)\n",
    "_result['_comz_av']=_result['Annual Value (AV) of commercial properties own'].apply(_log)\n",
    "_result['_comz_operate']=_result['Biz Operations from  commercial properties'].apply(_yesno)\n",
    "\n",
    "\n",
    "_result['_hardship_sentiment']=_result['Please describe hardship (if any)'].apply(_sentiment_of)\n",
    "_result['_ntuc_covid']=_result['Interested in NTUC Covid19 Programme'].apply(_interested)\n",
    "\n",
    "_result['LABEL']=_result['Final Outcome Combined'].apply(_label_outcome)\n",
    "\n",
    "\n",
    "_result = _result.drop(old_columns,axis=1)\n",
    "\n",
    "\n",
    "_result.to_csv ('_final.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine import Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 48)\n",
      "(30000, 3)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 15)                735       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 48        \n",
      "=================================================================\n",
      "Total params: 783\n",
      "Trainable params: 783\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = Machine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/150\n",
      "24000/24000 [==============================] - 5s 196us/sample - loss: 37.5352 - accuracy: 0.5135 - val_loss: 2.5214 - val_accuracy: 0.6080\n",
      "Epoch 2/150\n",
      "24000/24000 [==============================] - 2s 92us/sample - loss: 3.3529 - accuracy: 0.5585 - val_loss: 2.9906 - val_accuracy: 0.6025\n",
      "Epoch 3/150\n",
      "24000/24000 [==============================] - 2s 93us/sample - loss: 5.8236 - accuracy: 0.5697 - val_loss: 2.0804 - val_accuracy: 0.6550\n",
      "Epoch 4/150\n",
      "24000/24000 [==============================] - 2s 95us/sample - loss: 3.2074 - accuracy: 0.5782 - val_loss: 1.3877 - val_accuracy: 0.6342\n",
      "Epoch 5/150\n",
      "24000/24000 [==============================] - 2s 102us/sample - loss: 2.8571 - accuracy: 0.5930 - val_loss: 2.3484 - val_accuracy: 0.5625\n",
      "Epoch 6/150\n",
      "24000/24000 [==============================] - 2s 98us/sample - loss: 2.7991 - accuracy: 0.5895 - val_loss: 1.4578 - val_accuracy: 0.6643\n",
      "Epoch 7/150\n",
      "24000/24000 [==============================] - 2s 101us/sample - loss: 2.9729 - accuracy: 0.5885 - val_loss: 5.3851 - val_accuracy: 0.2593\n",
      "Epoch 8/150\n",
      "24000/24000 [==============================] - 2s 103us/sample - loss: 3.0744 - accuracy: 0.5895 - val_loss: 4.2046 - val_accuracy: 0.6178\n",
      "Epoch 9/150\n",
      "24000/24000 [==============================] - 2s 103us/sample - loss: 3.0336 - accuracy: 0.5895 - val_loss: 2.4932 - val_accuracy: 0.6343\n",
      "Epoch 10/150\n",
      "24000/24000 [==============================] - 3s 114us/sample - loss: 3.0523 - accuracy: 0.5871 - val_loss: 1.4220 - val_accuracy: 0.6290\n",
      "Epoch 11/150\n",
      "24000/24000 [==============================] - 3s 112us/sample - loss: 2.5850 - accuracy: 0.6001 - val_loss: 2.3906 - val_accuracy: 0.6312\n",
      "Epoch 12/150\n",
      "24000/24000 [==============================] - 3s 108us/sample - loss: 2.4476 - accuracy: 0.6038 - val_loss: 2.7288 - val_accuracy: 0.5603\n",
      "Epoch 13/150\n",
      "24000/24000 [==============================] - 2s 104us/sample - loss: 2.9869 - accuracy: 0.5830 - val_loss: 1.5979 - val_accuracy: 0.6678\n",
      "Epoch 14/150\n",
      "24000/24000 [==============================] - 3s 122us/sample - loss: 2.8647 - accuracy: 0.5888 - val_loss: 2.1973 - val_accuracy: 0.5883\n",
      "Epoch 15/150\n",
      "24000/24000 [==============================] - 3s 112us/sample - loss: 3.2056 - accuracy: 0.5864 - val_loss: 1.3790 - val_accuracy: 0.6667\n",
      "Epoch 16/150\n",
      "24000/24000 [==============================] - 2s 103us/sample - loss: 2.9840 - accuracy: 0.5925 - val_loss: 4.2495 - val_accuracy: 0.6363\n",
      "Epoch 17/150\n",
      "24000/24000 [==============================] - 2s 92us/sample - loss: 2.7410 - accuracy: 0.5938 - val_loss: 1.3661 - val_accuracy: 0.6542\n",
      "Epoch 18/150\n",
      "24000/24000 [==============================] - 2s 93us/sample - loss: 2.7262 - accuracy: 0.5929 - val_loss: 1.2955 - val_accuracy: 0.6628\n",
      "Epoch 19/150\n",
      "24000/24000 [==============================] - 2s 100us/sample - loss: 2.6291 - accuracy: 0.5992 - val_loss: 2.5925 - val_accuracy: 0.5685\n",
      "Epoch 20/150\n",
      "24000/24000 [==============================] - 2s 96us/sample - loss: 2.9646 - accuracy: 0.5909 - val_loss: 3.5988 - val_accuracy: 0.5665\n",
      "Epoch 21/150\n",
      "24000/24000 [==============================] - 2s 96us/sample - loss: 2.7136 - accuracy: 0.5988 - val_loss: 1.7961 - val_accuracy: 0.6355\n",
      "Epoch 22/150\n",
      "24000/24000 [==============================] - 3s 107us/sample - loss: 2.7116 - accuracy: 0.5943 - val_loss: 3.1701 - val_accuracy: 0.5887\n",
      "Epoch 23/150\n",
      "24000/24000 [==============================] - 3s 110us/sample - loss: 2.7673 - accuracy: 0.5938 - val_loss: 1.4382 - val_accuracy: 0.6388\n",
      "Epoch 24/150\n",
      "24000/24000 [==============================] - 2s 103us/sample - loss: 2.5682 - accuracy: 0.5933 - val_loss: 2.1485 - val_accuracy: 0.4927\n",
      "Epoch 25/150\n",
      "24000/24000 [==============================] - 3s 119us/sample - loss: 3.0349 - accuracy: 0.5871 - val_loss: 1.3951 - val_accuracy: 0.6392\n",
      "Epoch 26/150\n",
      "24000/24000 [==============================] - 3s 109us/sample - loss: 2.8255 - accuracy: 0.5924 - val_loss: 1.7877 - val_accuracy: 0.6090\n",
      "Epoch 27/150\n",
      "24000/24000 [==============================] - 3s 110us/sample - loss: 2.6322 - accuracy: 0.6019 - val_loss: 1.5860 - val_accuracy: 0.6723\n",
      "Epoch 28/150\n",
      "24000/24000 [==============================] - 3s 132us/sample - loss: 3.0255 - accuracy: 0.5836 - val_loss: 3.3037 - val_accuracy: 0.4407\n",
      "Epoch 29/150\n",
      "24000/24000 [==============================] - 3s 119us/sample - loss: 2.8740 - accuracy: 0.5867 - val_loss: 4.2621 - val_accuracy: 0.5748\n",
      "Epoch 30/150\n",
      "24000/24000 [==============================] - 3s 123us/sample - loss: 2.8867 - accuracy: 0.5972 - val_loss: 2.8997 - val_accuracy: 0.5587\n",
      "Epoch 31/150\n",
      "24000/24000 [==============================] - 3s 134us/sample - loss: 2.4868 - accuracy: 0.6016 - val_loss: 1.6486 - val_accuracy: 0.6523\n",
      "Epoch 32/150\n",
      "24000/24000 [==============================] - 4s 154us/sample - loss: 2.7633 - accuracy: 0.5938 - val_loss: 2.3730 - val_accuracy: 0.6608\n",
      "Epoch 33/150\n",
      "24000/24000 [==============================] - 3s 134us/sample - loss: 2.8738 - accuracy: 0.5938 - val_loss: 2.4825 - val_accuracy: 0.5992\n",
      "Epoch 34/150\n",
      "24000/24000 [==============================] - 3s 124us/sample - loss: 2.6759 - accuracy: 0.5978 - val_loss: 2.1987 - val_accuracy: 0.5622\n",
      "Epoch 35/150\n",
      "24000/24000 [==============================] - 3s 112us/sample - loss: 2.7010 - accuracy: 0.5940 - val_loss: 3.7623 - val_accuracy: 0.5717\n",
      "Epoch 36/150\n",
      "24000/24000 [==============================] - 3s 119us/sample - loss: 2.8791 - accuracy: 0.5980 - val_loss: 2.4721 - val_accuracy: 0.6355\n",
      "Epoch 37/150\n",
      "24000/24000 [==============================] - 3s 132us/sample - loss: 2.7799 - accuracy: 0.5932 - val_loss: 3.9715 - val_accuracy: 0.6602\n",
      "Epoch 38/150\n",
      "24000/24000 [==============================] - 3s 116us/sample - loss: 2.7069 - accuracy: 0.5981 - val_loss: 4.9402 - val_accuracy: 0.5160\n",
      "Epoch 39/150\n",
      "24000/24000 [==============================] - 3s 126us/sample - loss: 2.5206 - accuracy: 0.5992 - val_loss: 2.3733 - val_accuracy: 0.6560\n",
      "Epoch 40/150\n",
      "24000/24000 [==============================] - 3s 124us/sample - loss: 2.4154 - accuracy: 0.6064 - val_loss: 1.5999 - val_accuracy: 0.6447\n",
      "Epoch 41/150\n",
      "24000/24000 [==============================] - 3s 119us/sample - loss: 2.7637 - accuracy: 0.5950 - val_loss: 3.0471 - val_accuracy: 0.5967\n",
      "Epoch 42/150\n",
      "24000/24000 [==============================] - 2s 98us/sample - loss: 2.7955 - accuracy: 0.5887 - val_loss: 7.1310 - val_accuracy: 0.5467\n",
      "Epoch 43/150\n",
      "24000/24000 [==============================] - 3s 124us/sample - loss: 2.8993 - accuracy: 0.5932 - val_loss: 7.0260 - val_accuracy: 0.4693\n",
      "Epoch 44/150\n",
      "24000/24000 [==============================] - 3s 116us/sample - loss: 2.3950 - accuracy: 0.5985 - val_loss: 1.5636 - val_accuracy: 0.6717\n",
      "Epoch 45/150\n",
      "24000/24000 [==============================] - 3s 105us/sample - loss: 2.3521 - accuracy: 0.5973 - val_loss: 7.3068 - val_accuracy: 0.4397\n",
      "Epoch 46/150\n",
      "24000/24000 [==============================] - 3s 105us/sample - loss: 2.8826 - accuracy: 0.5935 - val_loss: 1.4219 - val_accuracy: 0.6068\n",
      "Epoch 47/150\n",
      "24000/24000 [==============================] - 2s 101us/sample - loss: 2.3636 - accuracy: 0.6014 - val_loss: 2.1217 - val_accuracy: 0.6033\n",
      "Epoch 48/150\n",
      "24000/24000 [==============================] - 3s 114us/sample - loss: 2.5381 - accuracy: 0.6052 - val_loss: 2.4523 - val_accuracy: 0.6430\n",
      "Epoch 49/150\n",
      "24000/24000 [==============================] - 2s 102us/sample - loss: 2.7156 - accuracy: 0.5918 - val_loss: 2.6095 - val_accuracy: 0.6705\n",
      "Epoch 50/150\n",
      "24000/24000 [==============================] - 2s 102us/sample - loss: 2.6502 - accuracy: 0.6008 - val_loss: 1.1301 - val_accuracy: 0.6450\n",
      "Epoch 51/150\n",
      "24000/24000 [==============================] - 2s 94us/sample - loss: 2.6183 - accuracy: 0.6049 - val_loss: 6.8417 - val_accuracy: 0.5467\n",
      "Epoch 52/150\n",
      "24000/24000 [==============================] - 3s 106us/sample - loss: 2.5361 - accuracy: 0.6026 - val_loss: 1.4748 - val_accuracy: 0.6737\n",
      "Epoch 53/150\n",
      "24000/24000 [==============================] - 2s 95us/sample - loss: 2.5506 - accuracy: 0.5978 - val_loss: 1.9125 - val_accuracy: 0.6182\n",
      "Epoch 54/150\n",
      "24000/24000 [==============================] - 2s 103us/sample - loss: 2.3677 - accuracy: 0.6073 - val_loss: 1.6909 - val_accuracy: 0.6792\n",
      "Epoch 55/150\n",
      "24000/24000 [==============================] - 2s 94us/sample - loss: 2.5665 - accuracy: 0.5964 - val_loss: 3.3266 - val_accuracy: 0.5605\n",
      "Epoch 56/150\n",
      "24000/24000 [==============================] - 2s 99us/sample - loss: 2.6253 - accuracy: 0.5965 - val_loss: 1.6963 - val_accuracy: 0.5860\n",
      "Epoch 57/150\n",
      "24000/24000 [==============================] - 3s 116us/sample - loss: 2.5796 - accuracy: 0.5955 - val_loss: 1.4801 - val_accuracy: 0.6742\n",
      "Epoch 58/150\n",
      "24000/24000 [==============================] - 2s 100us/sample - loss: 2.2772 - accuracy: 0.6034 - val_loss: 3.9387 - val_accuracy: 0.5512\n",
      "Epoch 59/150\n",
      "24000/24000 [==============================] - 2s 101us/sample - loss: 2.5586 - accuracy: 0.5969 - val_loss: 1.9840 - val_accuracy: 0.6535\n",
      "Epoch 60/150\n",
      "24000/24000 [==============================] - 3s 121us/sample - loss: 2.2628 - accuracy: 0.6021 - val_loss: 2.1156 - val_accuracy: 0.6213\n",
      "Epoch 61/150\n",
      "24000/24000 [==============================] - 2s 96us/sample - loss: 2.2286 - accuracy: 0.6053 - val_loss: 1.1173 - val_accuracy: 0.6550\n",
      "Epoch 62/150\n",
      "24000/24000 [==============================] - 3s 127us/sample - loss: 2.1086 - accuracy: 0.6054 - val_loss: 1.0635 - val_accuracy: 0.6528\n",
      "Epoch 63/150\n",
      "24000/24000 [==============================] - 2s 98us/sample - loss: 2.2803 - accuracy: 0.5970 - val_loss: 3.2870 - val_accuracy: 0.5590\n",
      "Epoch 64/150\n",
      "24000/24000 [==============================] - 2s 70us/sample - loss: 2.1902 - accuracy: 0.6029 - val_loss: 1.2531 - val_accuracy: 0.6777\n",
      "Epoch 65/150\n",
      "24000/24000 [==============================] - 2s 69us/sample - loss: 2.7581 - accuracy: 0.5841 - val_loss: 2.2197 - val_accuracy: 0.5690\n",
      "Epoch 66/150\n",
      "24000/24000 [==============================] - 2s 69us/sample - loss: 2.2771 - accuracy: 0.6012 - val_loss: 3.5604 - val_accuracy: 0.5467\n",
      "Epoch 67/150\n",
      "24000/24000 [==============================] - 2s 70us/sample - loss: 2.2700 - accuracy: 0.6057 - val_loss: 3.4160 - val_accuracy: 0.5670\n",
      "Epoch 68/150\n",
      "24000/24000 [==============================] - 2s 68us/sample - loss: 2.4255 - accuracy: 0.6001 - val_loss: 2.4919 - val_accuracy: 0.6117\n",
      "Epoch 69/150\n",
      "24000/24000 [==============================] - 2s 75us/sample - loss: 2.2219 - accuracy: 0.6038 - val_loss: 1.0084 - val_accuracy: 0.6748\n",
      "Epoch 70/150\n",
      "24000/24000 [==============================] - 2s 69us/sample - loss: 2.1676 - accuracy: 0.6022 - val_loss: 1.4886 - val_accuracy: 0.6815\n",
      "Epoch 71/150\n",
      "24000/24000 [==============================] - 2s 67us/sample - loss: 2.0768 - accuracy: 0.6048 - val_loss: 1.9821 - val_accuracy: 0.6357\n",
      "Epoch 72/150\n",
      "24000/24000 [==============================] - 2s 73us/sample - loss: 2.4394 - accuracy: 0.6017 - val_loss: 2.1678 - val_accuracy: 0.5112\n",
      "Epoch 73/150\n",
      "24000/24000 [==============================] - 2s 68us/sample - loss: 2.2026 - accuracy: 0.5970 - val_loss: 1.0452 - val_accuracy: 0.6762\n",
      "Epoch 74/150\n",
      "24000/24000 [==============================] - 2s 70us/sample - loss: 2.3678 - accuracy: 0.6007 - val_loss: 2.1167 - val_accuracy: 0.6640\n",
      "Epoch 75/150\n",
      "24000/24000 [==============================] - 2s 69us/sample - loss: 2.2641 - accuracy: 0.6045 - val_loss: 1.6918 - val_accuracy: 0.6405\n",
      "Epoch 76/150\n",
      "24000/24000 [==============================] - 2s 75us/sample - loss: 2.3482 - accuracy: 0.5956 - val_loss: 1.3194 - val_accuracy: 0.6747\n",
      "Epoch 77/150\n",
      "24000/24000 [==============================] - 2s 97us/sample - loss: 2.2245 - accuracy: 0.6059 - val_loss: 1.6131 - val_accuracy: 0.6495\n",
      "Epoch 78/150\n",
      "24000/24000 [==============================] - 2s 99us/sample - loss: 2.0378 - accuracy: 0.6047 - val_loss: 1.5583 - val_accuracy: 0.6628\n",
      "Epoch 79/150\n",
      "24000/24000 [==============================] - 3s 111us/sample - loss: 2.3507 - accuracy: 0.5940 - val_loss: 3.1715 - val_accuracy: 0.5508\n",
      "Epoch 80/150\n",
      "24000/24000 [==============================] - 3s 110us/sample - loss: 2.4183 - accuracy: 0.5945 - val_loss: 2.0289 - val_accuracy: 0.6658\n",
      "Epoch 81/150\n",
      "24000/24000 [==============================] - 3s 109us/sample - loss: 2.4229 - accuracy: 0.5976 - val_loss: 1.9564 - val_accuracy: 0.6512\n",
      "Epoch 82/150\n",
      "24000/24000 [==============================] - 3s 108us/sample - loss: 2.0054 - accuracy: 0.6106 - val_loss: 2.7813 - val_accuracy: 0.5383 2.0384 - \n",
      "Epoch 83/150\n",
      "24000/24000 [==============================] - 3s 135us/sample - loss: 2.0860 - accuracy: 0.6043 - val_loss: 2.1939 - val_accuracy: 0.6782\n",
      "Epoch 84/150\n",
      "24000/24000 [==============================] - 3s 118us/sample - loss: 2.4832 - accuracy: 0.5965 - val_loss: 1.9609 - val_accuracy: 0.6272\n",
      "Epoch 85/150\n",
      "24000/24000 [==============================] - 2s 90us/sample - loss: 2.0486 - accuracy: 0.6109 - val_loss: 2.7388 - val_accuracy: 0.5515\n",
      "Epoch 86/150\n",
      "24000/24000 [==============================] - 2s 99us/sample - loss: 2.0332 - accuracy: 0.6072 - val_loss: 1.4558 - val_accuracy: 0.6890\n",
      "Epoch 87/150\n",
      "24000/24000 [==============================] - 3s 117us/sample - loss: 2.2802 - accuracy: 0.6038 - val_loss: 2.5049 - val_accuracy: 0.5973\n",
      "Epoch 88/150\n",
      "24000/24000 [==============================] - 2s 82us/sample - loss: 2.1786 - accuracy: 0.5965 - val_loss: 2.4008 - val_accuracy: 0.5658\n",
      "Epoch 89/150\n",
      "24000/24000 [==============================] - 2s 71us/sample - loss: 2.0024 - accuracy: 0.6120 - val_loss: 1.7141 - val_accuracy: 0.6522\n",
      "Epoch 90/150\n",
      "24000/24000 [==============================] - 2s 70us/sample - loss: 2.2215 - accuracy: 0.5968 - val_loss: 1.5427 - val_accuracy: 0.6833\n",
      "Epoch 91/150\n",
      "24000/24000 [==============================] - 2s 73us/sample - loss: 2.2577 - accuracy: 0.6020 - val_loss: 2.8097 - val_accuracy: 0.5262\n",
      "Epoch 92/150\n",
      "24000/24000 [==============================] - 2s 70us/sample - loss: 1.9293 - accuracy: 0.6131 - val_loss: 3.2002 - val_accuracy: 0.4938\n",
      "Epoch 93/150\n",
      "24000/24000 [==============================] - 2s 69us/sample - loss: 2.2359 - accuracy: 0.6055 - val_loss: 1.7159 - val_accuracy: 0.6127\n",
      "Epoch 94/150\n",
      "24000/24000 [==============================] - 2s 72us/sample - loss: 2.3113 - accuracy: 0.5930 - val_loss: 2.5446 - val_accuracy: 0.4420\n",
      "Epoch 95/150\n",
      "24000/24000 [==============================] - 2s 74us/sample - loss: 1.7701 - accuracy: 0.6164 - val_loss: 2.6639 - val_accuracy: 0.5158\n",
      "Epoch 96/150\n",
      "24000/24000 [==============================] - 2s 70us/sample - loss: 2.1981 - accuracy: 0.5993 - val_loss: 1.7344 - val_accuracy: 0.6473\n",
      "Epoch 97/150\n",
      "24000/24000 [==============================] - 2s 71us/sample - loss: 2.0128 - accuracy: 0.6145 - val_loss: 1.7044 - val_accuracy: 0.5702\n",
      "Epoch 98/150\n",
      "24000/24000 [==============================] - 2s 72us/sample - loss: 1.9819 - accuracy: 0.6036 - val_loss: 1.6450 - val_accuracy: 0.6087\n",
      "Epoch 99/150\n",
      "24000/24000 [==============================] - 2s 74us/sample - loss: 1.8884 - accuracy: 0.6103 - val_loss: 1.4060 - val_accuracy: 0.6547\n",
      "Epoch 100/150\n",
      "24000/24000 [==============================] - 2s 71us/sample - loss: 2.0155 - accuracy: 0.6005 - val_loss: 1.2207 - val_accuracy: 0.6502\n",
      "Epoch 101/150\n",
      "24000/24000 [==============================] - 2s 69us/sample - loss: 2.0992 - accuracy: 0.5978 - val_loss: 1.0408 - val_accuracy: 0.6768\n",
      "Epoch 102/150\n",
      "24000/24000 [==============================] - 2s 69us/sample - loss: 2.2312 - accuracy: 0.6007 - val_loss: 1.7070 - val_accuracy: 0.5947\n",
      "Epoch 103/150\n",
      "24000/24000 [==============================] - 2s 67us/sample - loss: 1.9848 - accuracy: 0.6143 - val_loss: 1.6055 - val_accuracy: 0.6332\n",
      "Epoch 104/150\n",
      "24000/24000 [==============================] - 2s 73us/sample - loss: 1.9105 - accuracy: 0.6060 - val_loss: 1.0957 - val_accuracy: 0.6353\n",
      "Epoch 105/150\n",
      "24000/24000 [==============================] - 2s 85us/sample - loss: 1.7437 - accuracy: 0.6128 - val_loss: 1.1083 - val_accuracy: 0.6765\n",
      "Epoch 106/150\n",
      "24000/24000 [==============================] - 2s 86us/sample - loss: 2.0203 - accuracy: 0.6036 - val_loss: 3.7710 - val_accuracy: 0.5473\n",
      "Epoch 107/150\n",
      "24000/24000 [==============================] - 2s 85us/sample - loss: 1.9276 - accuracy: 0.6069 - val_loss: 0.9918 - val_accuracy: 0.6828\n",
      "Epoch 108/150\n",
      "24000/24000 [==============================] - 2s 83us/sample - loss: 1.8380 - accuracy: 0.6089 - val_loss: 1.7055 - val_accuracy: 0.6270\n",
      "Epoch 109/150\n",
      "24000/24000 [==============================] - 2s 79us/sample - loss: 1.9824 - accuracy: 0.6015 - val_loss: 1.7111 - val_accuracy: 0.5495\n",
      "Epoch 110/150\n",
      "24000/24000 [==============================] - 2s 82us/sample - loss: 1.8692 - accuracy: 0.6046 - val_loss: 1.7086 - val_accuracy: 0.6222\n",
      "Epoch 111/150\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 1.8045 - accuracy: 0.6105 - val_loss: 1.4971 - val_accuracy: 0.5798\n",
      "Epoch 112/150\n",
      "24000/24000 [==============================] - 2s 78us/sample - loss: 1.8576 - accuracy: 0.6074 - val_loss: 1.4945 - val_accuracy: 0.6435\n",
      "Epoch 113/150\n",
      "24000/24000 [==============================] - 2s 77us/sample - loss: 1.9851 - accuracy: 0.6117 - val_loss: 1.7996 - val_accuracy: 0.6552\n",
      "Epoch 114/150\n",
      "24000/24000 [==============================] - 2s 78us/sample - loss: 1.8842 - accuracy: 0.6097 - val_loss: 2.6766 - val_accuracy: 0.6142\n",
      "Epoch 115/150\n",
      "24000/24000 [==============================] - 2s 75us/sample - loss: 1.7179 - accuracy: 0.6177 - val_loss: 2.5777 - val_accuracy: 0.4823\n",
      "Epoch 116/150\n",
      "24000/24000 [==============================] - 2s 75us/sample - loss: 1.9821 - accuracy: 0.6047 - val_loss: 3.6613 - val_accuracy: 0.4985\n",
      "Epoch 117/150\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 1.6711 - accuracy: 0.6150 - val_loss: 1.3766 - val_accuracy: 0.6643\n",
      "Epoch 118/150\n",
      "24000/24000 [==============================] - 2s 73us/sample - loss: 1.9288 - accuracy: 0.6015 - val_loss: 2.5647 - val_accuracy: 0.5383\n",
      "Epoch 119/150\n",
      "24000/24000 [==============================] - 2s 82us/sample - loss: 1.5884 - accuracy: 0.6174 - val_loss: 2.7267 - val_accuracy: 0.5310\n",
      "Epoch 120/150\n",
      "24000/24000 [==============================] - 2s 75us/sample - loss: 1.8746 - accuracy: 0.6068 - val_loss: 8.5082 - val_accuracy: 0.5467\n",
      "Epoch 121/150\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 1.8137 - accuracy: 0.6121 - val_loss: 2.4703 - val_accuracy: 0.5123\n",
      "Epoch 122/150\n",
      "24000/24000 [==============================] - 2s 77us/sample - loss: 1.7480 - accuracy: 0.6134 - val_loss: 1.1684 - val_accuracy: 0.6707\n",
      "Epoch 123/150\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 1.5233 - accuracy: 0.6246 - val_loss: 1.0971 - val_accuracy: 0.6688\n",
      "Epoch 124/150\n",
      "24000/24000 [==============================] - 2s 80us/sample - loss: 1.7230 - accuracy: 0.6128 - val_loss: 0.8849 - val_accuracy: 0.6628\n",
      "Epoch 125/150\n",
      "24000/24000 [==============================] - 2s 75us/sample - loss: 1.7942 - accuracy: 0.6084 - val_loss: 3.3806 - val_accuracy: 0.4437\n",
      "Epoch 126/150\n",
      "24000/24000 [==============================] - 2s 74us/sample - loss: 1.9006 - accuracy: 0.6088 - val_loss: 1.8476 - val_accuracy: 0.6265\n",
      "Epoch 127/150\n",
      "24000/24000 [==============================] - 2s 75us/sample - loss: 1.6995 - accuracy: 0.6150 - val_loss: 2.3253 - val_accuracy: 0.5985\n",
      "Epoch 128/150\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 1.9107 - accuracy: 0.6095 - val_loss: 2.1422 - val_accuracy: 0.6818\n",
      "Epoch 129/150\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 1.6915 - accuracy: 0.6201 - val_loss: 0.9011 - val_accuracy: 0.6588\n",
      "Epoch 130/150\n",
      "24000/24000 [==============================] - 2s 77us/sample - loss: 1.8166 - accuracy: 0.6081 - val_loss: 1.0597 - val_accuracy: 0.6675\n",
      "Epoch 131/150\n",
      "24000/24000 [==============================] - 2s 83us/sample - loss: 1.7507 - accuracy: 0.6080 - val_loss: 1.3513 - val_accuracy: 0.6892\n",
      "Epoch 132/150\n",
      "24000/24000 [==============================] - 2s 77us/sample - loss: 1.7965 - accuracy: 0.6106 - val_loss: 1.3422 - val_accuracy: 0.6163\n",
      "Epoch 133/150\n",
      "24000/24000 [==============================] - 2s 74us/sample - loss: 1.7428 - accuracy: 0.6074 - val_loss: 2.0403 - val_accuracy: 0.5670\n",
      "Epoch 134/150\n",
      "24000/24000 [==============================] - 2s 80us/sample - loss: 1.7095 - accuracy: 0.6131 - val_loss: 1.5453 - val_accuracy: 0.6022\n",
      "Epoch 135/150\n",
      "24000/24000 [==============================] - 2s 79us/sample - loss: 1.7222 - accuracy: 0.6159 - val_loss: 1.8496 - val_accuracy: 0.6178\n",
      "Epoch 136/150\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 1.7953 - accuracy: 0.6098 - val_loss: 0.8306 - val_accuracy: 0.6897\n",
      "Epoch 137/150\n",
      "24000/24000 [==============================] - 2s 75us/sample - loss: 1.8114 - accuracy: 0.6050 - val_loss: 2.3971 - val_accuracy: 0.5500\n",
      "Epoch 138/150\n",
      "24000/24000 [==============================] - 2s 80us/sample - loss: 1.4630 - accuracy: 0.6234 - val_loss: 1.7126 - val_accuracy: 0.6788\n",
      "Epoch 139/150\n",
      "24000/24000 [==============================] - 2s 80us/sample - loss: 1.6922 - accuracy: 0.6080 - val_loss: 2.1490 - val_accuracy: 0.5438\n",
      "Epoch 140/150\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 1.7888 - accuracy: 0.6080 - val_loss: 0.8644 - val_accuracy: 0.6675\n",
      "Epoch 141/150\n",
      "24000/24000 [==============================] - 2s 85us/sample - loss: 1.5840 - accuracy: 0.6174 - val_loss: 1.1841 - val_accuracy: 0.6428\n",
      "Epoch 142/150\n",
      "24000/24000 [==============================] - 2s 79us/sample - loss: 1.5346 - accuracy: 0.6170 - val_loss: 0.9977 - val_accuracy: 0.6613\n",
      "Epoch 143/150\n",
      "24000/24000 [==============================] - 2s 77us/sample - loss: 1.5944 - accuracy: 0.6122 - val_loss: 2.4464 - val_accuracy: 0.5470\n",
      "Epoch 144/150\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 1.7001 - accuracy: 0.6089 - val_loss: 1.2329 - val_accuracy: 0.5813\n",
      "Epoch 145/150\n",
      "24000/24000 [==============================] - 2s 76us/sample - loss: 1.6632 - accuracy: 0.6079 - val_loss: 1.0987 - val_accuracy: 0.6260\n",
      "Epoch 146/150\n",
      "24000/24000 [==============================] - 2s 73us/sample - loss: 1.8014 - accuracy: 0.6034 - val_loss: 0.9850 - val_accuracy: 0.6435\n",
      "Epoch 147/150\n",
      "24000/24000 [==============================] - 2s 78us/sample - loss: 1.5775 - accuracy: 0.6148 - val_loss: 1.3588 - val_accuracy: 0.6488\n",
      "Epoch 148/150\n",
      "24000/24000 [==============================] - 2s 90us/sample - loss: 1.9261 - accuracy: 0.6003 - val_loss: 1.8863 - val_accuracy: 0.5318\n",
      "Epoch 149/150\n",
      "24000/24000 [==============================] - 2s 75us/sample - loss: 1.5560 - accuracy: 0.6212 - val_loss: 1.5913 - val_accuracy: 0.5245\n",
      "Epoch 150/150\n",
      "24000/24000 [==============================] - 2s 77us/sample - loss: 1.8129 - accuracy: 0.6125 - val_loss: 1.8143 - val_accuracy: 0.6122\n",
      "saved model in /Users/mengweetan/Desktop/devt/ai/ntuc/\n",
      "<tensorflow.python.keras.callbacks.History object at 0x11a16ef60>\n"
     ]
    }
   ],
   "source": [
    "m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "load_model = tf.keras.models.load_model\n",
    "model = load_model('_modelv2.h5',custom_objects={'tf': tf}, compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                735       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 64        \n",
      "=================================================================\n",
      "Total params: 799\n",
      "Trainable params: 799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.7826529e-01 4.4047785e-17 3.4771052e-05 2.1699933e-02]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#input = [0,11932,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0.0,1542,3.3010299956639813,0.0,3.681241237375587,0.0,3.462397997898956,0.0,5.012837224705172,4.0484029561527395,2,0,0,1,0,0,2710,0,1,0,0,0.0,0,0.0,0] #1lk\n",
    "input = [1,10224,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0.0,1177,4.792454727670386,4.091491094267951,4.685222065334621,2.552668216112193,3.9030899869919438,0.0,0.0,0.0,0,2,0,0,1,0,0,0,1,0,0,0.0,0,0.0,1] #1000\n",
    "#input = [1,23779,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,4.346352974450639,10491,0.0,0.0,4.013427127070696,0.0,0.0,0.0,4.621124329567078,4.0092383709684665,0,0,0,1,0,0,13043,0,0,1,0,0.0,0,0.0,0] #800\n",
    "#input = [1,13678,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0.0,386,0.0,0.0,3.97799780995874,4.17897694729317,3.547528576459782,0.0,4.89368965098515,4.354146870586911,1,0,0,1,0,0,2171,0,1,0,0,0.0,0,-0.07583333333333332,1] #800\n",
    "#input = [1,13336,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0.0,537,0.0,0.0,4.452430493699599,4.4123261221462435,0.0,0.0,4.655503396249793,3.3820170425748683,1,0,0,1,0,0,2500,0,1,0,0,0.0,0,0.03333333333333333,1] #1k\n",
    "input = [0,17792,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4.357934847000454,4920,4.556302500767287,0.0,4.477121254719663,0.0,3.8750612633917,0.0,4.832508912706237,4.230448921378274,2,2,0,1,0,0,8657,0,0,1,0,0.0,0,0.0,0] #800\n",
    "\n",
    "input = [0, 20822, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.8785217955012063, 0, 0, 0, 4.109747237713228, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, -1, -99, 0]\n",
    "input = [1, 20880, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 902, 3.964118143151485, 3.964118143151485, 3.2593549273080344, 3.2593549273080344, 3.3010299956639813, 3.3010299956639813, 3.964118143151485, 3.9242792860618816, 0, 0, 0, 1, 0, 0, 11275, 0, 1, 0, 0, 0, -1, 0.004444444444444445, 1]\n",
    "\n",
    "_i = np.reshape(input,(len(input),1))\n",
    "\n",
    "_a = model.predict([_i.T])\n",
    "print (_a)\n",
    "np.argmax(_a)  #0 = 0,1=400, 2=800, 3 = 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.y[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
